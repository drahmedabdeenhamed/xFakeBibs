{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee5f81f7-c915-4754-9a11-e4042245f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import statements \n",
    "import json\n",
    "import obonet\n",
    "from itertools import combinations \n",
    "from Bio import Medline\n",
    "import networkx as nx\n",
    "import string\n",
    "from textblob import TextBlob  \n",
    "\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import tree\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63974b6d-8293-4445-ab3a-439a2609ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment configurations\n",
    "# MAX_NUMBER_BIGRAMS = 30\n",
    "MAX_NUMBER_ARTICLE = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ce8bc1a-8191-4147-8c82-f02f98486f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing a medline file \n",
    "def parse_medline_rmap(medline_file):    \n",
    "    map_abstracts = {}    \n",
    "    pmid = ''\n",
    "    abstract = ''  \n",
    "    with open(medline_file) as medline_handle:\n",
    "        records = Medline.parse(medline_handle)\n",
    "        for record in records:         \n",
    "            keys = record.keys()            \n",
    "            if 'PMID' in keys and 'AB' in keys: \n",
    "\n",
    "                pmid = record['PMID']\n",
    "                abstract = record['AB']\n",
    "                \n",
    "                map_abstracts[pmid] = abstract.lower()\n",
    "    return map_abstracts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85f0e020-a6bb-4b94-b88d-b7500d99de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_gpt_api_data(json_file):\n",
    "\n",
    "    json_records_map = {}\n",
    "    # Open and read the JSON file\n",
    "    with open(json_file, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    # Now json_data is a list of dictionaries, each representing an item in the array\n",
    "    for item in json_data:\n",
    "        gpt_id = item['GPT-ID']\n",
    "        title = item['Title']\n",
    "        abstract = item['Abstract']\n",
    "        # json_records_map[gpt_id]=(title + \" \" + abstract)\n",
    "        json_records_map[gpt_id]=(title + \" \" + abstract)        \n",
    "    return json_records_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13080a90-1415-4f9e-ae19-a183512273b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_string_special_characters(s):\n",
    "      \n",
    "    # removes special characters with ' '\n",
    "    stripped = re.sub('[^a-zA-z\\s]', '', s)\n",
    "    stripped = re.sub('_', '', stripped)\n",
    "      \n",
    "    # Change any white space to one space\n",
    "    stripped = re.sub('\\s+', ' ', stripped)\n",
    "      \n",
    "    # Remove start and end white spaces\n",
    "    stripped = stripped.strip()\n",
    "    if stripped != '':\n",
    "            return stripped.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e603b3a6-895e-4887-9d4f-611ce9a333bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_abstracts = parse_medline_rmap('../dataset/pubmed-cancerandc-set-2015-2019.txt')\n",
    "cgpt_abstracts = parse_json_gpt_api_data('../dataset/cancer-gpt-apis.txt')\n",
    "\n",
    "# cleaning PubMed articles from special characters\n",
    "clean_pubmed_articles = []\n",
    "for abst in list(pubmed_abstracts.values())[0:]:\n",
    "    cleaned = remove_string_special_characters(abst)    \n",
    "    clean_pubmed_articles.append(cleaned)\n",
    "    \n",
    "# cleaning chatGPT articles from special characters\n",
    "clean_chatGPT_articles = []\n",
    "for abst in list(cgpt_abstracts.values())[0:]:\n",
    "    cleaned = remove_string_special_characters(abst)    \n",
    "    clean_chatGPT_articles.append(cleaned)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b71e1951-6355-4495-96f3-f11c6de17793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "although rare bronchopleural fistula bpf following anatomic lung resection is a serious complication associated with high rates of mortality risk factors for bpf include surgical approach neoadjuvant therapy diabetes mellitus and chronic obstructive pulmonary disease as neoadjuvant treatment is increasingly being administered to patients with locally advanced lung cancer and as more patients are being diagnosed with lung cancer at an older ageelderly patients present with a higher index of multiple comorbiditiesthe incidence of bpf among patients undergoing anatomic resection for lung cancer is expected to increase in this manuscript we detail risk factors and considerations for bpf and describe a stepwise approach to treat bpf following lobectomy for lung cancer\n"
     ]
    }
   ],
   "source": [
    "print(clean_pubmed_articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cd597f6-5b64-465a-940a-22512d16f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "special_list = ['abstract']\n",
    "\n",
    "def stopwords_rem_pubmed(clean_pubmed_training):\n",
    "    stopped_pubmed_training = []\n",
    "    for abst in clean_pubmed_training[:MAX_NUMBER_ARTICLE]:\n",
    "        valid_l = []\n",
    "        valid_rec = []\n",
    "        blob_object = TextBlob(abst)\n",
    "        list_tokens = blob_object.words\n",
    "\n",
    "        for token in list_tokens:        \n",
    "            if token not in stop_words:\n",
    "                valid_l.append(token)            \n",
    "        valid_rec = ' '.join(valid_l)\n",
    "        stopped_pubmed_training.append(valid_rec)\n",
    "    return stopped_pubmed_training\n",
    "    \n",
    "    \n",
    "def stopwords_rem_chatGPT_dataset(clean_chatGPT):    \n",
    "    stopped_chatGPT_training = []\n",
    "    for abst in clean_chatGPT_training[:MAX_NUMBER_ARTICLE]:\n",
    "        valid_l = []\n",
    "        valid_rec = []\n",
    "        blob_object = TextBlob(abst)\n",
    "        list_tokens = blob_object.words\n",
    "\n",
    "        for token in list_tokens:        \n",
    "            if (token not in stop_words) and (token not in special_list):\n",
    "                valid_l.append(token)            \n",
    "        valid_rec = ' '.join(valid_l)\n",
    "        stopped_chatGPT_training.append(valid_rec)   \n",
    "    return stopped_chatGPT_training\n",
    "\n",
    "\n",
    "def stopwords_rem_chatGPT_article(clean_chatGPT_article):    \n",
    "    stopped_chatGPT_training = []\n",
    "    valid_l = []\n",
    "    valid_rec = []\n",
    "    blob_object = TextBlob(clean_chatGPT_article)\n",
    "    list_tokens = blob_object.words\n",
    "\n",
    "    for token in list_tokens:        \n",
    "        if (token not in stop_words) and (token not in special_list):\n",
    "            valid_l.append(token)            \n",
    "    valid_rec = ' '.join(valid_l)\n",
    "    # stopped_chatGPT_training.append(valid_rec)   \n",
    "    return str(valid_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "756e0025-68d5-4820-afbb-3c220042d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202\n"
     ]
    }
   ],
   "source": [
    "pubmed_articles_ready = stopwords_rem_pubmed(clean_pubmed_articles)\n",
    "\n",
    "# print(len(stopped_pubmed_training))  \n",
    "gpt_articles_ready = []\n",
    "for article in clean_chatGPT_articles:\n",
    "    gpt_articles_ready.append(stopwords_rem_chatGPT_article(article))\n",
    "print(len(gpt_articles_ready))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8345cb7a-ac87-4af6-aafe-5fb4d2babe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pubmed_articles_ready[0])\n",
    "# print('-----')\n",
    "# print(gpt_articles_ready[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5ffe92e-af59-4d04-b6c3-9c318836e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting PubMed bigrams\n",
    "def compute_bigrams(training_articles):\n",
    "    list_bigrams = []\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range =(2, 2))\n",
    "    X1 = vectorizer.fit_transform(training_articles)\n",
    "    features = (vectorizer.get_feature_names_out())\n",
    "    # print(\"\\n\\nX1 : \\n\", X1.toarray())\n",
    "\n",
    "    # Applying TFIDF\n",
    "    # You can still get n-grams here\n",
    "    vectorizer = TfidfVectorizer(ngram_range = (2, 2))\n",
    "    X2 = vectorizer.fit_transform(training_articles)\n",
    "    scores = (X2.toarray())\n",
    "    # print(\"\\n\\nScores : \\n\", scores)\n",
    "\n",
    "    # Getting top ranking features\n",
    "    sums = X2.sum(axis = 0)\n",
    "    data1 = []\n",
    "    for col, term in enumerate(features):\n",
    "        data1.append( (term, sums[0, col] ))\n",
    "    ranking = pd.DataFrame(data1, columns = ['term', 'rank'])\n",
    "    words = (ranking.sort_values('rank', ascending = False))\n",
    "\n",
    "    bigram_ranks = {}\n",
    "    for index, row in words.iterrows():\n",
    "        # print(row['term'],'\\t\\t\\t',  row['rank'])\n",
    "\n",
    "        splits = row['term'].split()\n",
    "        bigram_ranks[row['rank']] = (splits[0], splits[1])\n",
    "\n",
    "    count = 0    \n",
    "    for k, v in bigram_ranks.items():\n",
    "        # if count < MAX_NUMBER_BIGRAMS:\n",
    "        #     # print(k,'\\t',  v)\n",
    "        #     count += 1\n",
    "        list_bigrams.append(v)\n",
    "    return bigram_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ff019e0-a5ba-4c93-b9ba-62f7b9065699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_training_model(training_articles):\n",
    "    bigrams_map_training = compute_bigrams(training_articles)\n",
    "    gpt_training_bigrams = bigrams_map_training.values()\n",
    "    \n",
    "    graph_training_model = nx.Graph()\n",
    "    graph_training_model.add_edges_from(list(gpt_training_bigrams))\n",
    "    \n",
    "    return graph_training_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ded8c1c2-3712-48c4-803c-7f828e9b62eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------- GPT Training Model --------\n",
      "Original node count:  559\n",
      "Original edge count:  1050\n",
      " -------- PubMed Training Model --------\n",
      "Original node count:  828\n",
      "Original edge count:  977\n"
     ]
    }
   ],
   "source": [
    "# construct a network training model from both datasets (gpt and pubmed)\n",
    "\n",
    "gpt_training_model = construct_training_model(gpt_articles_ready[:100])\n",
    "pubmed_training_model = construct_training_model(pubmed_articles_ready[:100])\n",
    "\n",
    "# ----------   Verifying GPT Training  Model ----------# \n",
    "print(' -------- GPT Training Model --------')\n",
    "node_count = len(gpt_training_model.nodes())\n",
    "edge_count = len(gpt_training_model.edges())\n",
    "print('Original node count: ', node_count)\n",
    "print('Original edge count: ', edge_count)\n",
    "\n",
    "# ----------   Verifying PubMed Training  Model ----------# \n",
    "print(' -------- PubMed Training Model --------')\n",
    "node_count = len(pubmed_training_model.nodes())\n",
    "edge_count = len(pubmed_training_model.edges())\n",
    "print('Original node count: ', node_count)\n",
    "print('Original edge count: ', edge_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ffffcb0-d548-4376-96d7-9354472b35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_giant_lcc(graph_training_model):\n",
    "    gcc = sorted(nx.connected_components(graph_training_model), key=len, reverse=True)\n",
    "    giant_cc = graph_training_model.subgraph(gcc[0])\n",
    "    return giant_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7da8e22-e4a9-4973-922d-bd411fa4ce72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------- GPT GIANT LCC Graph --------\n",
      "Graph with 489 nodes and 1008 edges\n",
      " -------- PUBMED GIANT LCC Graph --------\n",
      "Graph with 588 nodes and 842 edges\n"
     ]
    }
   ],
   "source": [
    "print(' -------- GPT GIANT LCC Graph --------')\n",
    "gpt_lcc = get_giant_lcc(gpt_training_model)\n",
    "print(gpt_lcc)\n",
    "\n",
    "print(' -------- PUBMED GIANT LCC Graph --------')\n",
    "pubmed_lcc = get_giant_lcc(pubmed_training_model)\n",
    "print(pubmed_lcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0950208d-636b-4784-b0a0-c1b8f4561eae",
   "metadata": {},
   "outputs": [],
   "source": [
    " # STEP2: -- compute individual articles bigrams -------\n",
    "def calibrate_model(ds_label, begin_index, end_index, training_graph, calibrate_set):\n",
    "    \n",
    "    training_graph_copy = training_graph.copy() \n",
    "\n",
    "    ratios_added_per_fold = []\n",
    "    for abst in calibrate_set[begin_index:end_index]:\n",
    "        \n",
    "        tokens = nltk.word_tokenize(abst)\n",
    "\n",
    "        # compute the bigrams\n",
    "        bigrams = list(nltk.bigrams(tokens))\n",
    "\n",
    "        # -------  check if the giant has the bigram components, add new edge \n",
    "        # -------          otherwise, don't add new edges\n",
    "        # -------  count how many nodes            \n",
    "        count = 0\n",
    "        added_edges = []\n",
    "        for bigram in bigrams:\n",
    "\n",
    "            if training_graph_copy.has_node(bigram[0]) and training_graph_copy.has_node(bigram[1]):\n",
    "\n",
    "                if not training_graph_copy.has_edge(bigram[0], bigram[1]):\n",
    "\n",
    "                    training_graph_copy.add_edge(bigram[0], bigram[1])\n",
    "                    count += 1\n",
    "                    added_edges.append((bigram[0], bigram[1]))\n",
    "        ratio_ = count / len(tokens)        \n",
    "        \n",
    "        ratios_added_per_fold.append(ratio_) \n",
    "        \n",
    "        training_graph_copy.remove_edges_from(added_edges)      \n",
    "    return ratios_added_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd014f6c-9a92-4e85-a279-78a8258b941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(tst_set_list):\n",
    "    average = sum(tst_set_list) / len(tst_set_list)        \n",
    "    formatted_avg = float(\"{:.5f}\".format(average))        \n",
    "    return formatted_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df86f04a-4d5e-4535-b810-1cadc3bb0e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the list is: 0.27947\n",
      "The average of the list is: 0.29009\n",
      "The average of the list is: 0.26738\n",
      "The average of the list is: 0.25622\n",
      "The average of the list is: 0.25135\n",
      "The average of the list is: 0.28374\n",
      "The average of the list is: 0.27115\n",
      "The average of the list is: 0.26867\n",
      "The average of the list is: 0.25155\n",
      "The average of the list is: 0.25541\n",
      "The average of the list is: 0.24857\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "gpt_means = []\n",
    "for index in range(100,MAX_NUMBER_ARTICLE):\n",
    "    label_prefix = 'TEST-'\n",
    "    if index % 100 == 0:\n",
    "        count += 1\n",
    "        calb_ratios_list = calibrate_model(label_prefix + str(count), index, index+100, gpt_lcc, gpt_articles_ready)\n",
    "        # print(calb_ratios_list)\n",
    "        tst_mean_g = calc_mean(calb_ratios_list) \n",
    "        print(\"The average of the list is:\", tst_mean_g)\n",
    "        gpt_means.append(tst_mean_g)\n",
    "        \n",
    "gpt_min_value = min(gpt_means)\n",
    "gpt_max_value = max(gpt_means)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d67982e6-5346-48f0-8317-96fb6c705464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15838\n",
      "0.15191\n",
      "0.16585\n",
      "0.15232\n",
      "0.16439\n",
      "0.16477\n",
      "0.15776\n",
      "0.15788\n",
      "0.15757\n",
      "0.15096\n",
      "0.15829\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "pubmed_means = []\n",
    "for index in range(100,MAX_NUMBER_ARTICLE):\n",
    "    label_prefix = 'TEST-'\n",
    "    if index % 100 == 0:\n",
    "        count += 1\n",
    "        calb_ratios_list = calibrate_model(label_prefix + str(count), index, index+100, pubmed_lcc, pubmed_articles_ready)\n",
    "        # print(calb_ratios_list)\n",
    "        tst_mean_p = calc_mean(calb_ratios_list) \n",
    "        # print(\"The average of the list is:\", tst_mean_p)\n",
    "        pubmed_means.append(tst_mean_p)\n",
    "        \n",
    "pubmed_min_value = min(pubmed_means)\n",
    "pubmed_max_value = max(pubmed_means) \n",
    "# print(gpt_means)\n",
    "for ratio in pubmed_means:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed318152-06ef-4e6e-8a70-aba811af55ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_an_article(article_text, training_graph):\n",
    "    \n",
    "    training_graph_copy = training_graph.copy()\n",
    "    \n",
    "    # chat_no_added_edges = []\n",
    "    # for abst in stopped_pubmed_training[begin_index:end_index]:\n",
    "\n",
    "    tokens = nltk.word_tokenize(article_text)\n",
    "\n",
    "    # compute the bigrams\n",
    "    bigrams = list(nltk.bigrams(tokens))\n",
    "\n",
    "    # -------  check if the giant has the bigram components, add new edge \n",
    "    # -------          otherwise, don't add new edges\n",
    "    # -------  count how many nodes    \n",
    "\n",
    "    count = 0\n",
    "    added_edges = []\n",
    "    for bigram in bigrams:\n",
    "\n",
    "        if training_graph_copy.has_node(bigram[0]) and training_graph_copy.has_node(bigram[1]):\n",
    "\n",
    "            if not training_graph_copy.has_edge(bigram[0], bigram[1]):\n",
    "\n",
    "                training_graph_copy.add_edge(bigram[0], bigram[1])\n",
    "                count += 1\n",
    "                added_edges.append((bigram[0], bigram[1]))\n",
    "    ratio_ = count / len(tokens)        \n",
    "    training_graph_copy.remove_edges_from(added_edges)\n",
    "        \n",
    "    return ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5000d5a-e4bf-4940-a3ec-7a68f557d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "MISCLASSIFIED:  0.0\n",
      "CORRECT CLASSIFIED:  1.0\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The average of the list is: 0.15191\n",
    "# The average of the list is: 0.16585\n",
    "misclassified = 0\n",
    "correct_classified = 0\n",
    "for article in gpt_articles_ready[200:MAX_NUMBER_ARTICLE]:\n",
    "    # print(type(article))\n",
    "    ratio_val = fit_an_article(article, gpt_lcc)\n",
    "    if ratio_val >= pubmed_max_value and ratio_val <= pubmed_max_value :       \n",
    "        misclassified+=1\n",
    "        # print('MISCLASSIFIED: Fit ratio for individual articles: ', ratio_val)\n",
    "    else:\n",
    "        correct_classified+=1\n",
    "        # print('CORRECT CLASS: Fit ratio for individual articles: ', ratio_val)\n",
    "print('-------------------------------------------------')        \n",
    "print('MISCLASSIFIED: ', misclassified/1000)\n",
    "print('CORRECT CLASSIFIED: ', correct_classified/1000)   \n",
    "print('-------------------------------------------------')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc6b890e-7be7-4214-ab38-809eae6018b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "MISCLASSIFIED:  0.03\n",
      "CORRECT CLASSIFIED:  9.97\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "misclassified = 0\n",
    "correct_classified = 0\n",
    "for article in pubmed_articles_ready[200:MAX_NUMBER_ARTICLE]:\n",
    "    # print(type(article))\n",
    "    ratio_val = fit_an_article(article, gpt_lcc)\n",
    "    if ratio_val >= gpt_min_value and ratio_val <= gpt_max_value:       \n",
    "        misclassified+=1\n",
    "        # print('MISCLASSIFIED: Fit ratio for individual articles: ', ratio_val)\n",
    "    else:\n",
    "        correct_classified+=1\n",
    "        # print('CORRECT CLASS: Fit ratio for individual articles: ', ratio_val)\n",
    "print('-------------------------------------------------')        \n",
    "print('MISCLASSIFIED: ', misclassified/100)\n",
    "print('CORRECT CLASSIFIED: ', correct_classified/100)   \n",
    "print('-------------------------------------------------')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8dbdf11-489f-4143-9c67-65320e99d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_range(point, range_start, range_end):\n",
    "    # Calculate the distance to the nearest endpoint of the range\n",
    "    distance = min(abs(point - range_start), abs(point - range_end))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12dcfac3-c5eb-43c2-83b7-fa9461538eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score(tp, tn, fp, fn):\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30ed6e22-56d9-48bd-a0d8-31adf88a5073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FP] [GPT ORIGIN: ] X PUBMED PREDICTED  =>  ratio: 0.13821138211382114 , evidence: GPT: thyroid cancer \n",
      "[FP] [GPT ORIGIN: ] X PUBMED PREDICTED  =>  ratio: 0.06349206349206349 , evidence: GPT: association mel\n",
      "[FP] [GPT ORIGIN: ] X PUBMED PREDICTED  =>  ratio: 0.12931034482758622 , evidence: GPT: association bla\n",
      "[FP] [GPT ORIGIN: ] X PUBMED PREDICTED  =>  ratio: 0.13157894736842105 , evidence: GPT: relationship pr\n",
      "[FP]: gpt_misclassified_as_pubmed 5 0.17105263157894737 evidence GPT: association lun\n",
      "[FP] [GPT ORIGIN: ] X PUBMED PREDICTED  =>  ratio: 0.14130434782608695 , evidence: GPT: impact cancer c\n",
      "[FP]: gpt_misclassified_as_pubmed 7 0.22807017543859648 evidence GPT: association chr\n",
      "[FP] [GPT ORIGIN: ] X PUBMED PREDICTED  =>  ratio: 0.14634146341463414 , evidence: GPT: impact cancer c\n",
      "---------------COUNTS---------------------------\n",
      "PUBMED CLASSIFIED (TP):  50\n",
      "CHATGPT CLASSIFIED (TN):  42\n",
      "[PUBMED ORIGINAL: ] X  GPT PREDICTED : (FN) 0\n",
      "[GPT ORIGINAL: ] X PUBMED PREDICTED : (FP) 8\n",
      "-------------------------------------------------\n",
      "F1 Score:  0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "# two classes classification\n",
    "\n",
    "two_classes_test_set = []\n",
    "\n",
    "for pubmed_article in pubmed_articles_ready[200:250]:\n",
    "    two_classes_test_set.append('PUBMED: ' + pubmed_article)\n",
    "\n",
    "for gpt_article in gpt_articles_ready[200:250]:\n",
    "    two_classes_test_set.append('GPT: ' + gpt_article)\n",
    "    \n",
    "\n",
    "count = 0\n",
    "chatgpt_class = 0\n",
    "pubmed_class = 0\n",
    "\n",
    "failed_to_classify = 0\n",
    "pubmed_misclassified_as_gpt = 0\n",
    "gpt_misclassified_as_pubmed = 0\n",
    "\n",
    "\n",
    "# RANGE 1: PUBMED\n",
    "range1_start = pubmed_min_value\n",
    "range1_end = pubmed_max_value\n",
    "\n",
    "# RANGE 2: GPT\n",
    "range2_start = gpt_min_value\n",
    "range2_end = gpt_max_value\n",
    "\n",
    "# The articles are labeled with evidence [\"PUBMED\" or \"GPT\"]\n",
    "# getting the first 20 characters is nothing by to show the actual label \n",
    "# and be sure that you have identified the correct label\n",
    "\n",
    "for article in two_classes_test_set:\n",
    "    \n",
    "    gpt_ratio_val    = fit_an_article(article, gpt_lcc)\n",
    "    pubmed_ratio_val = fit_an_article(article, pubmed_lcc)\n",
    "    \n",
    "    # Classifying GPT\n",
    "    if gpt_ratio_val >= range2_start and ratio_val <= range2_end :       \n",
    "        if article[:20].startswith('GPT'):\n",
    "            chatgpt_class+=1\n",
    "            # print('ChatGPT : Fit ratio for individual articles: ', gpt_ratio_val, 'evidence', article[:20])\n",
    "        else:\n",
    "            pubmed_misclassified_as_gpt+=1\n",
    "            \n",
    "    # Classifying PUBMED\n",
    "    elif pubmed_ratio_val >= range1_start and ratio_val <= range1_end:\n",
    "        if article[:20].startswith('PUBMED'):\n",
    "            pubmed_class += 1\n",
    "            # print('PUBMED : Fit ratio for individual articles: ', pubmed_ratio_val, 'evidence', article[:20])\n",
    "        else: \n",
    "            gpt_misclassified_as_pubmed+=1\n",
    "            print(\"[FP]: gpt_misclassified_as_pubmed\", gpt_misclassified_as_pubmed, pubmed_ratio_val, 'evidence', article[:20])\n",
    "            # print('PUBMED : Fit ratio for individual articles: ', pubmed_ratio_val, 'evidence', article[:20])\n",
    "        \n",
    "    else:\n",
    "        # Calculate distances\n",
    "        distance_to_range1 = distance_to_range(pubmed_ratio_val, range1_start, range1_end)\n",
    "        distance_to_range2 = distance_to_range(gpt_ratio_val, range2_start, range2_end) \n",
    "        \n",
    "        # print('distance to range 1: ', distance_to_range1)\n",
    "        # print('distance to range 2: ', distance_to_range2)        \n",
    "        \n",
    "        # RANGE 1: PUBMED ARTICLES SHOULD SLIDE IN HERE\n",
    "        # If ChatGPT slide in it is FLASE POSITIVE\n",
    "        if distance_to_range1 < distance_to_range2:\n",
    "            if article[:20].startswith('GPT'):\n",
    "                gpt_misclassified_as_pubmed+=1\n",
    "                # print(\"gpt_misclassified_as_pubmed\", gpt_misclassified_as_pubmed)\n",
    "                print('[FP] [GPT ORIGIN: ] X PUBMED PREDICTED  => ', 'ratio:', pubmed_ratio_val ,', evidence:', article[:20])                \n",
    "            else:   \n",
    "                # count+=1\n",
    "                pubmed_class += 1\n",
    "                # print('PUBMED CLASS PREDICTED => ', 'ratio:', pubmed_ratio_val , ', evidence:', article[:20])\n",
    "\n",
    "        # RANGE 2: GPT SHOULD ARTICLES SHOULD SLIDE IN HERE\n",
    "        elif distance_to_range2 < distance_to_range1:\n",
    "            if article[:20].startswith('PUBMED'):                \n",
    "                pubmed_misclassified_as_gpt+=1\n",
    "                print('[NP] [PUBMED ORIGIN: ] X GPT PREDICTED => ', 'ratio:', gpt_ratio_val , ', evidence:', article[:20]) \n",
    "                # print(\"pubmed_misclassified_as_gpt\", pubmed_misclassified_as_gpt)\n",
    "            else:\n",
    "                \n",
    "                chatgpt_class += 1\n",
    "                # print('GPT CLASS PREDICTED => ', 'ratio:', gpt_ratio_val , ' >> evidence:', article[:20])\n",
    "                # print(\"ELSE: chatgpt_class\", chatgpt_class)\n",
    "                \n",
    "\n",
    "    # print(' -------------------------------- ')\n",
    "    \n",
    "    \n",
    "print('---------------COUNTS---------------------------')    \n",
    "# print('Number of publications analyzed: ', count)\n",
    "print('PUBMED CLASSIFIED (TP): ', pubmed_class)   \n",
    "print('CHATGPT CLASSIFIED (TN): ', chatgpt_class)   \n",
    "print('[PUBMED ORIGINAL: ] X  GPT PREDICTED : (FN)', pubmed_misclassified_as_gpt) \n",
    "print('[GPT ORIGINAL: ] X PUBMED PREDICTED : (FP)', gpt_misclassified_as_pubmed)   \n",
    "print('-------------------------------------------------') \n",
    "    \n",
    "\n",
    "tp = pubmed_class\n",
    "tn = chatgpt_class\n",
    "fp = pubmed_misclassified_as_gpt\n",
    "fn = gpt_misclassified_as_pubmed\n",
    "\n",
    "\n",
    "# tp, tn, fp, fn\n",
    "print(\"F1 Score: \", compute_f1_score(tp, tn, fp, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4698f44f-4493-4cd1-a627-e7096b3cd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the exact training data: the first 100 from each \n",
    "# PUBMED is contributing first\n",
    "# ChaatGPT is contributing 2nd\n",
    "\n",
    "pubmed_training = pubmed_articles_ready[:100]\n",
    "gpt_training = gpt_articles_ready[:100]\n",
    "\n",
    "pubmed_training.extend(gpt_training)\n",
    "two_classes_training_set = gpt_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbf6faae-4d0c-467d-a0ce-358d82c0a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import algo_evals as ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67681f37-ab2d-4490-ade6-bad39c1ea9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Multinomial Naive Bayes\n",
      "TP: 11, FP: 39, FN: 25, TN: 25\n",
      "F1 Score: 0.43859649122807015\n",
      "\n",
      "Classifier: Linear SVM\n",
      "TP: 23, FP: 27, FN: 23, TN: 27\n",
      "F1 Score: 0.5192307692307693\n",
      "\n",
      "Classifier: Random Forest\n",
      "TP: 24, FP: 26, FN: 20, TN: 30\n",
      "F1 Score: 0.5660377358490566\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "TP: 20, FP: 30, FN: 25, TN: 25\n",
      "F1 Score: 0.47619047619047616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification performance of Two Classes Articles\n",
    "ae.classify(two_classes_training_set, two_classes_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d5d63-88a4-4bdb-b58c-a1191c25c0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42211b7d-0c98-4c89-81ae-d1ec25637e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e3bb0-e92f-4efa-884a-2adaf0957bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5e5dc-4150-4959-ac17-9efe826b462e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
